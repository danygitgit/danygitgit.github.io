<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.6.2">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2018-01-30T13:30:06+00:00</updated><id>http://localhost:4000/</id><title type="html">毛毛虫_Wendy</title><subtitle>Record ideas and knowledge</subtitle><author><name>Wendy</name></author><entry><title type="html">新浪微博爬虫</title><link href="http://localhost:4000/2018/01/30/weibospider/" rel="alternate" type="text/html" title="新浪微博爬虫" /><published>2018-01-30T00:00:00+00:00</published><updated>2018-01-30T00:00:00+00:00</updated><id>http://localhost:4000/2018/01/30/weibospider</id><content type="html" xml:base="http://localhost:4000/2018/01/30/weibospider/">&lt;p&gt;详解新浪微博爬取过程&lt;/p&gt;

&lt;h3 id=&quot;前言&quot;&gt;前言&lt;/h3&gt;

&lt;p&gt;因为科研需要，我从16年8月起就开始跟微博数据打交道，所以从那时开始就不得不想尽办法爬取微博数据，我爬取的内容主要是：博文、发博账号、发文时间、爬取时间、点赞数/评论数/转发数，详情如图1。经过长时间的总结和实验，我完善了切实可行的&lt;a href=&quot;https://github.com/DWJWendy/Weibo_Spider&quot;&gt;爬虫代码&lt;/a&gt;，代码被我放在github上，同样你也可以在我的个人博客open-source里面查看到weibospider项目。&lt;/p&gt;

&lt;p&gt;欢迎大家fork和star我的项目,&lt;strong&gt;&lt;a href=&quot;https://github.com/DWJWendy/Weibo_Spider&quot;&gt;项目地址&lt;/a&gt;&lt;/strong&gt;，谢谢！&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/blog/2018-01-30-1.png&quot; alt=&quot;图1&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;环境&quot;&gt;环境&lt;/h3&gt;

&lt;p&gt;linux+Python3.6+mongo&lt;/p&gt;

&lt;p&gt;但是万变不离其中，更改一下便可以用于其他语言和环境。&lt;/p&gt;
&lt;h3 id=&quot;预登陆&quot;&gt;预登陆&lt;/h3&gt;

&lt;p&gt;我们都知道微博数据需要先登录才能爬取，而我们解决的办法是使用微博预登陆获得登录需要的必要参数，这一部分在/Prelogin.py 实现的。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;def login_weibo(nick , pwd) :
    #==========================获取servertime , pcid , pubkey , rsakv===========================
    # 预登陆请求，获取到若干参数
    prelogin_url = 'http://login.sina.com.cn/sso/prelogin.php?entry=weibo&amp;amp;callback=sinaSSOController.preloginCallBack&amp;amp;su=%s&amp;amp;rsakt=mod&amp;amp;checkpin=1&amp;amp;client=ssologin.js(v1.4.15)&amp;amp;_=1400822309846' % nick
    preLogin = getData(prelogin_url)
    # 下面获取的四个值都是接下来要使用的
    servertime = re.findall('&quot;servertime&quot;:(.*?),' , preLogin.decode('utf-8'))[0]
    pubkey = re.findall('&quot;pubkey&quot;:&quot;(.*?)&quot;,' , preLogin.decode('utf-8'))[0]
    rsakv = re.findall('&quot;rsakv&quot;:&quot;(.*?)&quot;,' ,preLogin.decode('utf-8'))[0]
    nonce = re.findall('&quot;nonce&quot;:&quot;(.*?)&quot;,' , preLogin.decode('utf-8'))[0]

    #===============对用户名和密码加密================
    # 好，你已经来到登陆新浪微博最难的一部分了，如果这部分没有大神出来指点一下，那就真是太难了，我也不想多说什么，反正就是各种加密，最后形成了加密后的su和sp
    su = base64.b64encode(bytes(urllib.request.quote(nick) , encoding = 'utf-8'))
    rsaPublickey = int(pubkey , 16)
    key = rsa.PublicKey(rsaPublickey , 65537)
    #稍微说一下的是在我网上搜到的文章中，有些文章里并没有对拼接起来的字符串进行bytes，这是python3的新方法好像是。rsa.encrypt需要一个字节参数，这一点和之前不一样。其实上面的base64.b64encode也一样
    message = bytes(str(servertime) + '\t' + str(nonce) + '\n' + str(pwd) , encoding = 'utf-8')
    sp = binascii.b2a_hex(rsa.encrypt(message , key))
    #=======================登录=======================
    #param就是激动人心的登陆post参数，这个参数用到了若干个上面第一步获取到的数据，可说的不多
    param = {'entry' : 'weibo' , 'gateway' : 1 , 'from' : '' , 'savestate' : 7 , 'useticket' : 1 , 'pagerefer' : 'http://login.sina.com.cn/sso/logout.php?entry=miniblog&amp;amp;r=http%3A%2F%2Fweibo.com%2Flogout.php%3Fbackurl%3D' , 'vsnf' : 1 , 'su' : su , 'service' : 'miniblog' , 'servertime' : servertime , 'nonce' : nonce , 'pwencode' : 'rsa2' , 'rsakv' : rsakv , 'sp' : sp , 'sr' : '1680*1050' ,
             'encoding' : 'UTF-8' , 'prelt' : 961 , 'url' : 'http://weibo.com/ajaxlogin.php?framelogin=1&amp;amp;callback=parent.sinaSSOController.feedBackUrlCallBack'}
    # 这里就是使用postData的唯一一处，也很简单
    s = postData('http://login.sina.com.cn/sso/login.php?client=ssologin.js(v1.4.15)' , param)
    # 好了，当你的代码执行到这里时，已经完成了大部分了，可是有很多爬虫童鞋跟我一样还就栽在了这里，假如你跳过这里直接去执行获取粉丝的这几行代码你就会发现你获取的到还是让你登陆的页面，真郁闷啊，我就栽在这里长达一天啊
    # 好了，我们还是继续。这个urll是登陆之后新浪返回的一段脚本中定义的一个进一步登陆的url，之前还都是获取参数和验证之类的，这一步才是真正的登陆，所以你还需要再一次把这个urll获取到并用get登陆即可
    urll = re.findall(&quot;location.replace\(\'(.*?)\'\);&quot; , s)[0]
    getData(urll)
    #======================获取粉丝====================
    # 如果你没有跳过刚才那个urll来到这里的话，那么恭喜你！你成功了，接下来就是你在新浪微博里畅爬的时候了，获取到任何你想获取到的数据了！
    # 可以尝试着获取你自己的微博主页看看，你就会发现那是一个多大几百kb的文件了

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;但是需要注意这行代码，有时候会出现匹配不成功的问题，所以这个时候你需要打印出s检查一下问题&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;urll = re.findall(&quot;location.replace\(\'(.*?)\'\);&quot; , s)[0]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;获取爬取账号的url&quot;&gt;获取爬取账号的URL&lt;/h3&gt;

&lt;p&gt;这个过程你需要分析账号的规律，因为不同微博账号，可以代码规律不一样，url获取通过查看元素，查找到对应页面的地址。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/blog/2018-01-30-2.png&quot; alt=&quot;图2&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;解析页码&quot;&gt;解析页码&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    def get_content(self,text):
        mongo = MongoDB()
        reg = '&lt;span class=&quot;nt&quot;&gt;&amp;lt;em&amp;gt;&lt;/span&gt;(\d+)&lt;span class=&quot;nt&quot;&gt;&amp;lt;/em&amp;gt;&lt;/span&gt;'
        logger.info('解析获取网页数据...')
        content = json.loads(text.decode(&quot;ascii&quot;))['data']
        soup = BeautifulSoup(&quot;&lt;span class=&quot;nt&quot;&gt;&amp;lt;html&amp;gt;&amp;lt;head&amp;gt;&amp;lt;/head&amp;gt;&amp;lt;body&amp;gt;&lt;/span&gt;&quot; + content + &quot;&lt;span class=&quot;nt&quot;&gt;&amp;lt;/body&amp;gt;&amp;lt;/html&amp;gt;&lt;/span&gt;&quot;, &quot;lxml&quot;)
        tmp = soup.find_all(&quot;div&quot;, attrs={&quot;class&quot;: &quot;WB_detail&quot;})
        tmp2 = soup.find_all(&quot;div&quot;, attrs={&quot;class&quot;:&quot;WB_handle&quot;})
        if len(tmp) &amp;gt; 0 :
            for i in range(len(tmp)):
                item = {}
                item[&quot;nickname&quot;] = tmp[i].find(&quot;div&quot;, attrs={&quot;class&quot;: &quot;WB_info&quot;}).find(&quot;a&quot;).get_text()
                item[&quot;Post&quot;] = tmp[i].find(&quot;div&quot;, attrs={&quot;class&quot;: &quot;WB_text W_f14&quot;}).get_text().replace(&quot;\n&quot;, &quot;&quot;).replace(&quot; &quot;,&quot;&quot;).replace( &quot;\u200b&quot;, &quot;&quot;)
                # -*- 爬取发布时间 -*-
                item[&quot;Pubtime&quot;] = tmp[i].find(&quot;a&quot;, attrs={&quot;class&quot;: &quot;S_txt2&quot;}).get(&quot;title&quot;)
                # -*- 爬取转发数 -*-
                if re.findall(reg,str(tmp2[i].find(&quot;span&quot;, attrs={&quot;class&quot;: &quot;line S_line1&quot;,&quot;node-type&quot;:&quot;forward_btn_text&quot;})), re.S):
                    item[&quot;Transfer_num&quot;] = int(re.findall(reg,str(tmp2[i].find(&quot;span&quot;, attrs={&quot;class&quot;: &quot;line S_line1&quot;,&quot;node-type&quot;:&quot;forward_btn_text&quot;})), re.S)[0])
                else:
                    item[&quot;Transfer_num&quot;] = 0
                # -*- 爬取评论数 -*-
                if re.findall(reg, str(tmp2[i].find(&quot;span&quot;, attrs={&quot;class&quot;: &quot;line S_line1&quot;, &quot;node-type&quot;: &quot;comment_btn_text&quot;})), re.S):
                    item[&quot;Comment_num&quot;] = int(re.findall(reg, str(tmp2[i].find(&quot;span&quot;, attrs={&quot;class&quot;: &quot;line S_line1&quot;, &quot;node-type&quot;: &quot;comment_btn_text&quot;})), re.S)[0])
                else:
                    item[&quot;Comment_num&quot;] = 0
                # -*- 爬取点赞数 -*-
                if re.findall(reg, str(tmp2[i].find(&quot;span&quot;, attrs={&quot;node-type&quot;: &quot;like_status&quot;})), re.S):
                    item[&quot;Like_num&quot;] = int(re.findall(reg, str(tmp2[i].find(&quot;span&quot;, attrs={&quot;node-type&quot;: &quot;like_status&quot;})), re.S)[0])
                else:
                    item[&quot;Like_num&quot;] = 0
                item[&quot;Scraltime&quot;] = time.strftime(&quot;%Y-%m-%d %H:%M:%S&quot;, time.localtime())
                if mongo.process_item(item)== &quot;null&quot;:
                    break
                else:
                    continue

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;定时登录设置&quot;&gt;定时登录设置&lt;/h3&gt;

&lt;p&gt;这一部分是我参考别人的代码，你也可以用参考其他方式&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;import sched, time
from program.Spider import Weibo_Spider
from program.Prelogin import getData
from program.logfile import logger


# 初始化sched模块的scheduler类
# 第一个参数是一个可以返回时间戳的函数，第二个参数可以在定时未到达之前阻塞。
schedule = sched.scheduler(time.time, time.sleep)

def domain():
    weibospider = Weibo_Spider()
    ID_urls = weibospider.ID_urls
    for i in range(len(ID_urls)):
        for j in range(len(ID_urls[i])):
            logger.info('正在爬取第'+str(i)+&quot;个账号 第&quot;+str(j+1)+&quot;条网页&quot;)
            weibospider.get_content(text=getData(ID_urls[i][j]))

def perform(inc):
    schedule.enter(inc, 0, perform, (inc,))
    domain()  # 需要周期执行的函数

def mymain():
    schedule.enter(0, 0, perform, (86400,))
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;预览结果&quot;&gt;预览结果&lt;/h3&gt;

&lt;p&gt;更改微博账号以及你自己url地址和微博账号id，然后运行/main.py文件，爬取过程如下图。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;if __name__ == &quot;__main__&quot;:
    mymain()
    schedule.run()  # 开始运行，直到计划时间队
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;/images/blog/2018-01-30-3.png&quot; alt=&quot;图3&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;tips&quot;&gt;Tips&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;微博账号可以自己去淘宝买，如果爬取的内容比较多最好多买几个换着用。&lt;/li&gt;
  &lt;li&gt;前面也说了有时候正则匹配会出现问题，我也不知道为啥会时不时不能用，总的来说用起来没什么毛病。&lt;/li&gt;
  &lt;li&gt;个人觉得这些代码可以scrapy框架再整理一下。&lt;/li&gt;
  &lt;li&gt;如果大家发现还有什么毛病也欢迎联系我dengwenjun818@gmail.com。&lt;/li&gt;
&lt;/ul&gt;</content><author><name>Wendy</name></author><summary type="html">详解新浪微博爬取过程</summary></entry><entry><title type="html">如何利用github page快速搭建个人博客</title><link href="http://localhost:4000/2018/01/28/githubpage-and-blog/" rel="alternate" type="text/html" title="如何利用github page快速搭建个人博客" /><published>2018-01-28T00:00:00+00:00</published><updated>2018-01-28T00:00:00+00:00</updated><id>http://localhost:4000/2018/01/28/githubpage%20and%20blog</id><content type="html" xml:base="http://localhost:4000/2018/01/28/githubpage-and-blog/">&lt;p&gt;快速搭建个人博客&lt;/p&gt;

&lt;h2 id=&quot;背景&quot;&gt;背景&lt;/h2&gt;
&lt;p&gt;本来计划在简书或者csdn上一个博客用来记录一些读书笔记，就上知乎搜了一下哪个平台更好用，当时有大神推荐可以用github page自己搭建一个博客平台，随即我就查阅如何利用github page搭建个人博客，经过几天修改，大功告成了，下面就是我的博客地址。&lt;/p&gt;
&lt;ul class=&quot;task-list&quot;&gt;
  &lt;li class=&quot;task-list-item&quot;&gt;&lt;input type=&quot;checkbox&quot; class=&quot;task-list-item-checkbox&quot; disabled=&quot;disabled&quot; checked=&quot;checked&quot; /&gt;http://mmcwendy.info&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;注:地址是毛毛虫_Wendy的简写，欢迎大家fork和star&lt;/strong&gt;&lt;/p&gt;

&lt;h2 id=&quot;使用github-page搭建博客&quot;&gt;使用github page搭建博客&lt;/h2&gt;
&lt;h2 id=&quot;github-page&quot;&gt;Github page&lt;/h2&gt;
&lt;p&gt;github page是面向用户、组织和项目开放的公共静态页面搭建托管服务，站点可以被免费托管在 Github 上，你可以选择使用 Github Pages 默认提供的域名 github.io 或者自定义域名来发布站点，更便利地是你直接从你的GitHub存储库托管。只需编辑和推送你的blog，并且你的更改是实时的。&lt;/p&gt;
&lt;h3 id=&quot;搭建流程&quot;&gt;搭建流程&lt;/h3&gt;
&lt;h4 id=&quot;第一步创建仓库&quot;&gt;第一步:创建仓库&lt;/h4&gt;
&lt;p&gt;在创建仓库之前，默认你有github账号以及会基础的git命令能够上传代码，如果不会，请参考廖雪峰git教程【&lt;a href=&quot;https://www.liaoxuefeng.com/wiki/0013739516305929606dd18361248578c67b8067c8c017b000&quot;&gt;资料1&lt;/a&gt;】。&lt;/p&gt;
&lt;h4 id=&quot;方式-1&quot;&gt;方式 1:&lt;/h4&gt;
&lt;p&gt;你只需要登录GitHub并创建一个名为username .github.io 的新存储库 ，其中username是GitHub上的用户名（如图1）。
&lt;strong&gt;注意：如果存储库的第一部分不完全符合你的用户名，则不起作用，因此请确保正确无误。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/blog/2018-01-28-1.png&quot; alt=&quot;图1&quot; /&gt;&lt;/p&gt;

&lt;p&gt;然后你可以参考许多模板【参考模板&lt;a href=&quot;http://jekyllthemes.org&quot;&gt;素材1&lt;/a&gt;，&lt;a href=&quot;https://hexo.io/themes/&quot;&gt;素材2&lt;/a&gt;】，基于模板进行修改，打造属于自己风格的网站，我这个人比较看颜值，单选模板都选了一天，真心累。&lt;/p&gt;

&lt;h4 id=&quot;方式-2&quot;&gt;方式 2:&lt;/h4&gt;
&lt;p&gt;当然你也可以直接fork我的项目【&lt;a href=&quot;https://github.com/DWJWendy/DWJWendy.github.io&quot;&gt;地址&lt;/a&gt;】，然后将我的项目名改成你的github用户名.github.io,按照 GitHub Pages 的规定，名称为 username.github.io 的项目的 master 分支，或者其它名称的项目的 gh-pages 分支可以自动生成 GitHub Pages 页面。正常情况下，你可以在本地测试启动程序:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;进入项目目录下:&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;cd DWJWendy.github.io
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;ul&gt;
  &lt;li&gt;启动:&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;bundle exec jekyll serve
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;然后你可以通过127.0.0.1:4000在浏览器中访问到网页，如图2&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/blog/2018-01-28-2.png&quot; alt=&quot;图2&quot; /&gt;&lt;/p&gt;

&lt;p&gt;有关jekyll的具体内容参考【&lt;a href=&quot;http://jekyllcn.com/&quot;&gt;资料2&lt;/a&gt;】&lt;/p&gt;

&lt;h4 id=&quot;第二步修改模板&quot;&gt;第二步:修改模板&lt;/h4&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;修改配置。&lt;/p&gt;

    &lt;p&gt;网站的配置基本都集中在 _config.yml 文件中，将其中与个人信息相关的部分替换成你自己的，比如网站的 url、title、subtitle 和第三方评论模块的配置等。&lt;/p&gt;

    &lt;p&gt;&lt;strong&gt;评论模块：&lt;/strong&gt; 目前支持 disqus、gitment 和 gitalk，选用其中一种就可以了，推荐使用 gitment。它们各自的配置指南链接在 _config.yml 文件的 Comments 一节里都贴出来了，搭建过程【&lt;a href=&quot;https://imsun.net/posts/gitment-introduction/&quot;&gt;资料3&lt;/a&gt;】&lt;/p&gt;

    &lt;p&gt;&lt;strong&gt;注意：&lt;/strong&gt; 如果使用 disqus，因为 disqus 处理用户名与域名白名单的策略存在缺陷，请一定将 disqus.username 修改成你自己的，否则请将该字段留空。
&lt;img src=&quot;/images/blog/2018-01-28-5.png&quot; alt=&quot;图3&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;删除我的文章与图片。&lt;/p&gt;

    &lt;p&gt;如下文件夹中除了 template.md 文件外，都可以全部删除，然后添加你自己的内容。&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;_posts 文件夹中是我已发布的博客文章。&lt;/li&gt;
      &lt;li&gt;_drafts 文件夹中是我尚未发布的博客文章。&lt;/li&gt;
      &lt;li&gt;_wiki 文件夹中是我已发布的 wiki 页面。&lt;/li&gt;
      &lt;li&gt;images 文件夹中是我的文章和页面里使用的图片。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;修改「关于」页面。&lt;/p&gt;

    &lt;p&gt;pages/about.md 文件内容对应网站的「关于」页面，里面的内容多为个人相关，将它们替换成你自己的信息，包括 _data 目录下的 skills.yml 和 social.yml 文件里的数据。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;增加博客阅读统计功能。
使用的是leancloud,它是一个一站式后端云服务. 包括云存储、数据分析、用户关系、消息推送、即时通信等现代应用基础模块，因为只用存储博文阅读统计数，所以我用了数据存储模块，我的修改是直接参照这篇博客的，非常简单【&lt;a href=&quot;http://blog.csdn.net/u013553529/article/details/63357382&quot;&gt;资料4&lt;/a&gt;】&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;第三步上传&quot;&gt;第三步:上传&lt;/h4&gt;
&lt;p&gt;当你的修改完成后，你就可以进入项目下，并在终端输入相关的git命令将其上传到之前建立的仓库中&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;#进入项目目录
cd DWJWendy.github.io
#上传代码(依次在终端输入下面命令)
git init
git add --all
git commit -m &quot;first version&quot;
git remote add origin git@github.com:DWJWendy/DWJWendy.github.io.git
git git push -u origin master

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;然后你就可以在浏览器输入你的域名就可以访问你的博客，博客建立好你只需要自己写博客，然后按照上述方式传到github上，你新的博文既可以被别人访问了，如图3我的博客。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/blog/2018-01-28-4.png&quot; alt=&quot;图4&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;域名&quot;&gt;域名&lt;/h2&gt;
&lt;p&gt;说说我在这里踩的坑吧:我忘记&lt;strong&gt;域名需要解析&lt;/strong&gt;，哈哈哈真是超级搞笑……&lt;/p&gt;

&lt;p&gt;最初我选择github page主要是它不用服务器，不要域名就可以搭建自己的博客，但是大神小白告诉我他去Godaddy上买的域名，果然还非常的便宜，我只用了7元就买了 mmcwendy.info,有效期1年。&lt;/p&gt;

&lt;p&gt;再说域名解析，虽然曾经在计算机网络的课程上知道这个名词，但还真是第一次解析，我就直接找了资源【&lt;a href=&quot;https://www.zhihu.com/question/31377141&quot;&gt;资料5&lt;/a&gt;】，按照教程来还是非常简单的，这个是我的域名解析图3&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/blog/2018-01-28-3.png&quot; alt=&quot;图5&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;注意事项&quot;&gt;注意事项&lt;/h2&gt;

&lt;ol&gt;
  &lt;li&gt;虽然有很好的模板，但是很多东西还是需要自己的理解，了解最基本的原理，避免走弯路。&lt;/li&gt;
  &lt;li&gt;不是仅仅将上面的内容改了就可以的，你还需要注意一些细节，比如文件路径/comment.html里面的部分代码也需要修改。&lt;/li&gt;
  &lt;li&gt;在使用这个模板之前，你需要在本地安装Bower和Bundler，安装的教程可以在网上找一下，这个很简单，两行代码就可以搞定。&lt;/li&gt;
  &lt;li&gt;博文编辑使用markdown来编写。
    &lt;h2 id=&quot;一点小想法&quot;&gt;一点小想法&lt;/h2&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;看颜值选了好多模板，最终确定了这个模板，主要是网站的结构比较清晰，可以直接跟github想的项目直接相连，并且博客可以根据内容打上不同的tag，可能是机器学习学多了，非常喜欢这个分类明确的东西，另外，它的wiki部分让我非常喜欢，并且可以实时评论，如果有人评论了博文还会有email提醒，很多都是现成的应用，但是组合在一起就觉得特别棒。另外，对我而言，之前并没有用过markdown，这一篇博文用markdown写感觉markdown写起来还真是很方便，推荐。&lt;/p&gt;

&lt;h2 id=&quot;致谢&quot;&gt;致谢&lt;/h2&gt;

&lt;p&gt;本博客外观
基于 &lt;a href=&quot;http://dongchuan.github.io&quot;&gt;DONGChuan&lt;/a&gt; 
和 &lt;a href=&quot;http://mazhuang.org/&quot;&gt;Zhuang Ma&lt;/a&gt;
修改，非常感谢！&lt;/p&gt;</content><author><name>Wendy</name></author><summary type="html">快速搭建个人博客</summary></entry></feed>